{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install gensim  \n",
    "#! pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using tk instead.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "This data is about \"Lista de precios\" from electrical field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"Lista de precios word2vec.txt\",\"r\",encoding='utf-8')\n",
    "corpus = text_file.readlines()\n",
    "random.shuffle(corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word and tokens\n",
    "We will convert all of the words into lower-case using NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "data = []\n",
    "for doc in corpus:\n",
    "    t = []\n",
    "    for word in nltk.tokenize.word_tokenize(doc,language=\"spanish\"):\n",
    "        t.append(word.lower())\n",
    "    data.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unidades', 'de', 'obra', 'ingenieria', 'y', 'obras', 'de', 'distribución']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model\n",
    "We are going to use gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SkipGram\n",
    "Creating a SikipGra method Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(data,vector_size=100, window=5,min_count=5,sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "Compare similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99276\n",
      "0.954768\n",
      "0.99447864\n",
      "0.8342199\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('poste','madera'))\n",
    "print(model.wv.similarity('kva','kv'))\n",
    "print(model.wv.similarity('poste','montaje'))\n",
    "print(model.wv.similarity('cable','precios'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the vector for a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_15568\\2760820246.py:2: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  word_vectors.word_vec('poste')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.20059785,  0.11278027, -0.07441311,  0.1422241 , -0.11879149,\n",
       "       -0.24864164,  0.15658547,  0.26585075, -0.14554498, -0.27847844,\n",
       "        0.08352139, -0.12401766,  0.09816351,  0.04716201, -0.04990553,\n",
       "       -0.11632436,  0.12220698, -0.23120986, -0.15066807, -0.32741946,\n",
       "       -0.02226929,  0.0207325 ,  0.08792902, -0.06576914,  0.00531124,\n",
       "       -0.03992412, -0.1199858 , -0.1587133 , -0.12957661, -0.09448987,\n",
       "        0.07515287,  0.01558147,  0.19144884, -0.13571484, -0.04840292,\n",
       "        0.19639423, -0.01304033, -0.14905684, -0.11828177, -0.08448145,\n",
       "        0.05726487, -0.20362283, -0.06399065, -0.02193841,  0.18674952,\n",
       "       -0.11188079, -0.0160448 ,  0.08549301,  0.01480161,  0.11716761,\n",
       "        0.22016124, -0.02673917, -0.00819193,  0.11385458, -0.1722633 ,\n",
       "        0.2084154 ,  0.17727394, -0.00713337, -0.09620961,  0.14633164,\n",
       "       -0.02572851,  0.00629757,  0.09253932, -0.00404375, -0.24400717,\n",
       "        0.0558572 ,  0.04975931,  0.17482637, -0.1885932 ,  0.19967903,\n",
       "        0.00199664,  0.08066717,  0.2461771 ,  0.01334263,  0.16260004,\n",
       "        0.1373725 ,  0.00411262,  0.03654412, -0.09575965,  0.05448133,\n",
       "       -0.12483111,  0.0318042 ,  0.02005058,  0.20503703, -0.08959301,\n",
       "        0.12722068,  0.07373575,  0.21684308,  0.21252617,  0.0676004 ,\n",
       "        0.1752197 ,  0.1507252 ,  0.01287778,  0.06188653,  0.2882558 ,\n",
       "        0.07452372, -0.00065238, -0.15231906,  0.1014104 ,  0.01292583],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors.word_vec('poste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of words similar to a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('existentes', 0.9979122877120972), (';', 0.9977399110794067), ('civil', 0.9977132678031921), ('acuerdo', 0.9977064728736877), ('6', 0.9976826310157776), ('exterior', 0.9975786209106445), ('río', 0.9975457787513733), ('equipo', 0.9975296258926392), ('campos', 0.9975120425224304), ('linea', 0.9974679946899414)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar('cámara'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word cloud\n",
    "3D graphs of words we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = [\n",
    "    'poste','montaje','centro','cable','vereda','madera','conductor','transformador','cámara','tablero','existentes'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_15568\\2469902762.py:4: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  vectors.append(word_vectors.word_vec(v))\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "\n",
    "for v in vocabulario:\n",
    "    vectors.append(word_vectors.word_vec(v))\n",
    "print(type(vectors))\n",
    "vectors = np.array(vectors)\n",
    "print(type(vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning the 100 dimension vector into a 3 dimension with principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_vectors = pca.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a 3D plot to see the position of every word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,9))\n",
    "ax = fig.add_subplot(111,projection='3d')\n",
    "for i in range(len(pca_vectors)):\n",
    "    w = pca_vectors[i]\n",
    "    ax.scatter(w[0],w[1],w[2])\n",
    "    ax.text(w[0],w[1],w[2],vocabulario[i],fontsize=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_15568\\3896596588.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display,HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container:{width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container:{width:100% !important;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
